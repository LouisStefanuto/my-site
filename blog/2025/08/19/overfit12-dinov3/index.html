
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Personal website of Louis Stefanuto">
      
      
      
      
        <link rel="prev" href="../../../06/25/overfit11-v-jepa-2/">
      
      
      
      <link rel="icon" href="../../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.18">
    
    
      
        <title>Overfit#12: DINOv3 - Louis Stefanuto</title>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/stylesheets/main.7e37652d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#overfit12-dinov3" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../.." title="Louis Stefanuto" class="md-header__button md-logo" aria-label="Louis Stefanuto" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Louis Stefanuto
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Overfit#12: DINOv3
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
    
      <div class="md-header__source">
        <a href="https://github.com/LouisStefanuto" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    Github
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../about/" class="md-tabs__link">
        
  
  
    
  
  About

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../../" class="md-tabs__link">
          
  
  
  Posts

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../.." title="Louis Stefanuto" class="md-nav__button md-logo" aria-label="Louis Stefanuto" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Louis Stefanuto
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/LouisStefanuto" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    Github
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../about/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    About
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Posts
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Posts
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      <a href="../../../../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Index
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Post series
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            Post series
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/alphafold/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AlphaFold
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/chemistry/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chemistry
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/computer-vision/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Computer Vision
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/diffusion-models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Diffusion models
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/drug-discovery/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Drug Discovery
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/embedding/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Embedding
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/llm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LLM
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/reinforcement-learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Reinforcement Learning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/robotics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Robotics
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/ssl/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    SSL
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/video/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Video
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
                
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#motivation" class="md-nav__link">
    <span class="md-ellipsis">
      Motivation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dinov3-is-dinov2s-extension" class="md-nav__link">
    <span class="md-ellipsis">
      DINOv3 is DINOv2's extension
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gram-anchoring" class="md-nav__link">
    <span class="md-ellipsis">
      Gram Anchoring
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Gram Anchoring">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#gram-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Gram Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intuition" class="md-nav__link">
    <span class="md-ellipsis">
      Intuition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gram-anchoring-loss" class="md-nav__link">
    <span class="md-ellipsis">
      Gram Anchoring Loss
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-distillation" class="md-nav__link">
    <span class="md-ellipsis">
      Model distillation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-alignment" class="md-nav__link">
    <span class="md-ellipsis">
      Text alignment
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#benchmarking" class="md-nav__link">
    <span class="md-ellipsis">
      Benchmarking
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      References
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
  <div class="md-content md-content--post" data-md-component="content">
    <div class="md-sidebar md-sidebar--post" data-md-component="sidebar" data-md-type="navigation">
      <div class="md-sidebar__scrollwrap">
        <div class="md-sidebar__inner md-post">
          <nav class="md-nav md-nav--primary">
            <div class="md-post__back">
              <div class="md-nav__title md-nav__container">
                <a href="../../../../" class="md-nav__link">
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
                  <span class="md-ellipsis">
                    Back to index
                  </span>
                </a>
              </div>
            </div>
            
              <div class="md-post__authors md-typeset">
                
                  <div class="md-profile md-post__profile">
                    <span class="md-author md-author--long">
                      <img src="https://github.com/LouisStefanuto.png" alt="Louis Stefanuto">
                    </span>
                    <span class="md-profile__description">
                      <strong>
                        
                          Louis Stefanuto
                        
                      </strong>
                      <br>
                      Creator
                    </span>
                  </div>
                
              </div>
            
            <ul class="md-post__meta md-nav__list">
              <li class="md-nav__item md-nav__item--section">
                <div class="md-post__title">
                  <span class="md-ellipsis">
                    Metadata
                  </span>
                </div>
                <nav class="md-nav">
                  <ul class="md-nav__list">
                    <li class="md-nav__item">
                      <div class="md-nav__link">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 19H5V8h14m-3-7v2H8V1H6v2H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2h-1V1m-1 11h-5v5h5z"/></svg>
                        <time datetime="2025-08-19 00:00:00+00:00" class="md-ellipsis">August 19, 2025</time>
                      </div>
                    </li>
                    
                    
                      <li class="md-nav__item">
                        <div class="md-nav__link">
                          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9 3v15h3V3zm3 2 4 13 3-1-4-13zM5 5v13h3V5zM3 19v2h18v-2z"/></svg>
                          <span class="md-ellipsis">
                            in
                            
                              <a href="../../../../category/ssl/">SSL</a>, 
                              <a href="../../../../category/computer-vision/">Computer Vision</a>, 
                              <a href="../../../../category/embedding/">Embedding</a></span>
                        </div>
                      </li>
                    
                    
                      
                      <li class="md-nav__item">
                        <div class="md-nav__link">
                          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 20a8 8 0 0 0 8-8 8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8m0-18a10 10 0 0 1 10 10 10 10 0 0 1-10 10C6.47 22 2 17.5 2 12A10 10 0 0 1 12 2m.5 5v5.25l4.5 2.67-.75 1.23L11 13V7z"/></svg>
                          <span class="md-ellipsis">
                            
                              8 min read
                            
                          </span>
                        </div>
                      </li>
                    
                  </ul>
                </nav>
              </li>
            </ul>
            
          </nav>
          
        </div>
      </div>
    </div>
    <article class="md-content__inner md-typeset">
      
        
  



  
  


<h1 id="overfit12-dinov3"><strong>Overfit#12:</strong> DINOv3</h1>
<p><a href="./"><img alt="dinov3" src="../../../../images/12/main.jpg" /></a></p>
<!-- more -->

<h2 id="motivation">Motivation</h2>
<p>Self-Supervized Learning is a promising avenue for training large text/image/video general embedding models. SSL leverages huge datasets of unannotated data leading to more general models with emerging properties.</p>
<p>NLP scientists showed that scaling data and compute leads to stronger and more powerful models. Yet in the image field, despite datasets getting larger and larger, scaling beyond the 1B-parameter frontier has not yet been as successful.</p>
<p>In fact, many scaling attempts showed that global features keep improving with scaling (image-level representations), but that <strong>local features tend to degrade with scaling</strong>. In other words, scaling leads to better embedding models for image-level downstream tasks like classification, but it doesn't work as well for patch-level downstream tasks like segmentation (see the figures below).</p>
<figure>
<p><img alt="scaling issues" src="../../../../images/12/scaling_issues.png" width="600" /></p>
<figcaption>Image from DINOv3 paper.</figcaption>
</figure>
<figure>
<p><img alt="scaling issues" src="../../../../images/12/issues.jpg" width="600" /></p>
<figcaption>(pink) Classification accuracy on ImageNet1K.<br>(purple) Segmentation performance on VOC.<br>Image from DINOv3 paper.</figcaption>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In this post, I will focus on the additions of DINOv3<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup> and give special attention to <strong>Gram Anchoring</strong>, a simple regularization loss, that helps mitigate these issues. I already covered DINOv2<sup id="fnref:2"><a class="footnote-ref" href="#fn:2">2</a></sup> in details in a past post. If you are interested, I recommend having a look: <strong><a href="../../../01/13/overfit9-dinov2-explained-learning-robust-visual-features-without-supervision/">DINOv2 post ðŸ¦–ðŸ¦–</a></strong>.</p>
</div>
<hr />
<h2 id="dinov3-is-dinov2s-extension">DINOv3 is DINOv2's extension</h2>
<div class="admonition success">
<p class="admonition-title">Let's start by summarizing DINOv2 ...</p>
</div>
<p>DINOv2 uses a discriminative training procedure. At training, two random crops are extracted from each image. Each crop is fed through a student/teacher model. The student goal is to minimize the distance between the two view embeddings, at image-level <span class="arithmatex">\(\mathcal{L}_{DINO}\)</span> and at patch-level <span class="arithmatex">\(\mathcal{L}_{iBOT}\)</span>. The teacher is derived from the student using an EMA of its weights. DINOv2 also uses a Koleo regularizer <span class="arithmatex">\(\mathcal{L}_{koleo}\)</span> to encourage features within a batch to spread, and SwAV centering.</p>
<p>This gives rise to a multi-term pretraining loss:</p>
<div class="arithmatex">\[
\mathcal{Loss} = \mathcal{L}_{DINO} + \alpha \mathcal{L}_{iBOT} + \beta \mathcal{L}_{koleo}
\]</div>
<div class="admonition note">
<p class="admonition-title">The Meta team reuses the exact same DINOv2 loss to pretrain DINOv3. But ...</p>
</div>
<p>DINOv3 is essentially applying scaling laws to DINOv2: 10x more data (~100M images <span class="arithmatex">\(\rightarrow\)</span> ~1000M images), and 7x more parameters (1B <span class="arithmatex">\(\rightarrow\)</span> 7B). When scaling up DINOv2, the research team made two observations:</p>
<ul>
<li>
<p>At mid-training (~200k steps), <strong>patch-level similarities are already well structured</strong>.</p>
<blockquote>
<p>At this stage, similar patches have similar embeddings. They may not be perfect embeddings that compress all patch information, but their similarity relationships are meaningful.</p>
</blockquote>
</li>
<li>
<p>As training progresses toward 1M steps, <strong>global features continue to improve</strong>, but <strong>local similarities start to collapse</strong>.  </p>
<blockquote>
<p>At end-training, similar patches have <strong>less similar embeddings</strong>. The feature map has somehow degraded.</p>
</blockquote>
</li>
</ul>
<figure>
<p><img alt="scaling issues" src="../../../../images/12/scaling_issues3.png" width="600" /></p>
<figcaption>Image from DINOv3 paper.</figcaption>
</figure>
<p><span class="arithmatex">\(\rightarrow\)</span> What we need is a way to enforce similar patches to keep their embeddings similar.</p>
<div class="admonition quote">
<p class="admonition-title">But we have no labels... so how can we do that?</p>
</div>
<h2 id="gram-anchoring">Gram Anchoring</h2>
<p>In DINOv3, Meta introduces <strong>Gram Anchoring</strong>, a regularization technique to enforce feature maps to remain smooth, even when scaling up model size. As we'll see, Gram Anchoring is surprisingly simple. To explain it, letâ€™s first introduce the <strong>Gram Matrix</strong>.</p>
<h3 id="gram-matrix">Gram Matrix</h3>
<p>Let <span class="arithmatex">\(A\)</span> be an image. Let's divide it into <span class="arithmatex">\(N\)</span> patches (like in Vision Transformers) and let's compute their embeddings <span class="arithmatex">\(v_1, v_2, \dots, v_N\)</span>.</p>
<p>The <strong>Gram matrix</strong> <span class="arithmatex">\(G \in \mathbb{R}^{N \times N}\)</span> is defined as:</p>
<div class="arithmatex">\[
G_{ij} = \langle v_i, v_j \rangle
\]</div>
<p>This matrix captures the <strong>relative similarities between patches</strong>, independent of absolute positions.</p>
<figure>
<p><img alt="gram matrix" src="https://upload.wikimedia.org/wikipedia/commons/0/00/Gram_matrix.svg" width="400" /></p>
<figcaption>Gram Matrix.<br>Image from Wikipedia.</figcaption>
</figure>
<h3 id="intuition">Intuition</h3>
<div class="admonition quote">
<p class="admonition-title">Why is this Gram Matrix useful?</p>
</div>
<p>At ~200k steps, <strong>patch similarities are at their best</strong>: they reflect meaningful relationships between parts of an image. So here is the idea:</p>
<!-- As training continues, **global representations get stronger** (good for classification), but **patch-level consistency drifts** (bad for segmentation). Without constraints, the student forgets these useful local relations, even though they were already learned earlier. -->

<ul>
<li>Use the Gram matrix of an earlier checkpoint <strong>as a reference</strong>.  </li>
<li>Regularize the student so that its patch similarity structure remains close to this reference, even at later stages of training.  </li>
</ul>
<p>This way, the student can continue improving features while preserving local consistency. <strong>Gram Anchoring constrains similarities rather than raw embeddings</strong>.</p>
<figure>
<p><img alt="scaling issues" src="../../../../images/12/scaling_issues2.png" width="600" /></p>
<figcaption>Image from DINOv3 paper.</figcaption>
</figure>
<h3 id="gram-anchoring-loss">Gram Anchoring Loss</h3>
<div class="admonition note">
<p class="admonition-title">We are doing Deep Learning, so we need a loss. Let's rephrase our intuitions in mathematical terms.</p>
</div>
<p>At a given step <span class="arithmatex">\(t\)</span>, we store the teacherâ€™s Gram matrix <span class="arithmatex">\(G^{teacher}_t\)</span> and enforce the student to maintain a similar patch similarity structure:</p>
<div class="arithmatex">\[
\mathcal{L}_{gram} = \| G^{student}_t - G^{teacher}_t \|^2 = \left\| \mathbf{X}_S \cdot \mathbf{X}_S^{\top} - \mathbf{X}_G \cdot \mathbf{X}_G^{\top} \right\|^{2}
\]</div>
<p>This acts as an <strong>anchor</strong>: the student can freely learn new features, but <strong>patch-level relations cannot drift too far</strong>.  </p>
<p>In DINOv3, this loss is only added after 1M training steps, during what is called a post-training phase. <strong>Surprisingly, the effect is immediate</strong>: the model recovers local consistency in a few epochs, without any degradation in global features (see the green curve in the figure below).</p>
<div class="admonition quote">
<p><figure markdown>
<img alt="losses" src="../../../../images/12/losses.png" width="700" />
</figure></p>
<p><figure markdown>
<img alt="gram" src="../../../../images/12/gram.png" width="700" />
<figcaption>Images from DINOv3 paper.</figcaption>
</figure></p>
</div>
<p>Other techniques are combined on top of Gram Anchoring to boost performance on higher resolution images (orange curve), while minimizing the training budget:</p>
<ul>
<li><strong>Post-training at higher resolution</strong> (512, 768 instead of 256) helps learning how to embed larger images. It can be seen as context extension for LLMs.</li>
<li><strong>Upscaling images and then interpolating Gram matrices</strong> gives smoother references for the Gram loss.</li>
<li><strong>RoPE-box jittering</strong>: basically adding noise in ROPE embeddings to get a more robust model at varying input sizes.</li>
</ul>
<div class="admonition success">
<p class="admonition-title">Key takeaway</p>
<p>Gram Anchoring is a constraint that forces the studentâ€™s patch similarity to imitate that of a past checkpoint. The 1M-step student embeddings can evolve freely, but their <strong>patch similarity structure remains close</strong> to the reference, preserving local consistency.</p>
</div>
<h2 id="model-distillation">Model distillation</h2>
<p>If you don't have the compute resources to run the 7B model, don't worry! Meta also released distilled ViT and ConvNeXT checkpoints in a wide range of sizes (from 29M to 7B parameters).</p>
<div class="admonition quote">
<p><figure markdown>
<img alt="distilled models" src="../../../../images/12/distilled_models.png" width="700" />
<figcaption>Image from DINOv3 paper.</figcaption>
</figure></p>
</div>
<p>A particularly clever contribution of the DINOv3 paper is its multi-student distillation strategy. Traditionally, student models are distilled one at a time, which requires repeated and expensive queries to the teacher. Instead, DINOv3 trains multiple students in parallel, amortizing the teacherâ€™s forward passes across them. This significantly reduces the overall compute cost.</p>
<p>On top of that, they optimize GPU allocation by adapting the number of GPUs per student according to model size, which minimizes idle time and ensures efficient utilization of resources.</p>
<div class="admonition quote">
<p><figure markdown>
<img alt="distillation" src="../../../../images/12/distillation.png" width="700" />
<figcaption>Image from DINOv3 paper.</figcaption>
</figure></p>
</div>
<h2 id="text-alignment">Text alignment</h2>
<p>Aligning visual embedding models with text means learning a shared embedding space for both modalities. Some methods, such as CLIP, retrain models from scratch, while others make use of pretrained backbones, frozen or fine-tuned.</p>
<p>Using the LiT training paradigm<sup id="fnref:3"><a class="footnote-ref" href="#fn:3">3</a></sup>, the authors of DINOv3 adopted the latter approach and aligned their ViT-L model with text. On global textâ€“image alignment tasks, the model performs strongly, though it falls slightly short of the current state of the art, such as SigLIP2 and Perception Encoder.</p>
<p>Alignment can also be evaluated at <strong>patch-level</strong> using segmentation tasks. Due to its excellent dense embeddings, it is not a surprise to see DINOv3 give SOTA performance on such benchmarks.</p>
<div class="admonition success">
<p class="admonition-title">Key Takeaway</p>
<p>The text-aligned DINOv3 is a strong candidate if you interested in zero-shot segmentation from text prompts.</p>
<p>If you are just looking for a general-purpose multimodal embedding model, CLIP variants such as SigLIP2 may be a better fit.</p>
</div>
<div class="admonition quote">
<p><figure markdown>
<img alt="text alignemnt" src="../../../../images/12/text_alignment.png" width="700" />
<figcaption>When aligned with text, segmentation is the task where DINOv3 particularly excels. For classification and retrieval, better and cheaper alternatives exist.<br>Image from DINOv3 paper.</figcaption>
</figure></p>
</div>
<h2 id="benchmarking">Benchmarking</h2>
<p>I won't cover the rest of the benchmarks in depth, because (1) it would be too long and because (2) the paper does it better. In a nutshell they show that DINOv3 is SOTA in most computer vision benchmarks: classification, detection, segmentation, 3D tasks, ...</p>
<p>The DINOv3 training recipe also shows strong performance on geospatial data and even sets the new state of the art on some benchmarks like SatLidar1M val, SatLidar1M test and Open-Canopy. Note that two satellite imagery checkpoints were published with the paper.</p>
<div class="admonition quote">
<p><figure markdown>
<img alt="bench" src="../../../../images/12/benchmarks.png" width="700" />
<figcaption>Image from DINOv3 paper.</figcaption>
</figure></p>
</div>
<hr />
<div class="admonition note">
<p class="admonition-title">Concluding and key takeaways</p>
<ul>
<li>DINOv3 is the result of scaling the DINOv2 recipe on 10x more data and compute.</li>
<li>Gram Anchoring appears as a simple yet efficient solution to the local embedding degradation observed in former scaling attempts. Its contrastive loss takes advantage of the high-quality early-stage local capabilities of the teacher.</li>
<li>Scaling resolution at the end of the training is a good tradeoff to boost model performance/usability while limiting training costs.</li>
<li>Meta's benchmarking work is seriously impressive.</li>
</ul>
</div>
<h2 id="references">References</h2>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p><strong>DINOv3</strong>: SimÃ©oni, O., Vo, H. V., Seitzer, M., Baldassarre, F., Oquab, M., Jose, C., ... &amp; Bojanowski, P. (2025). <a href="https://arxiv.org/abs/2508.10104">DINOv3</a>. arXiv preprint arXiv:2508.10104.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:2">
<p><strong>DINOv2</strong>: Oquab, M., Darcet, T., Moutakanni, T., Vo, H., Szafraniec, M., Khalidov, V., ... &amp; Bojanowski, P. (2023). <a href="https://arxiv.org/pdf/2304.07193">Dinov2: Learning robust visual features without supervision</a>. arXiv preprint arXiv:2304.07193.&#160;<a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:3">
<p><strong>LiT</strong>: Xiaohua Zhai, Xiao Wang, Basil Mustafa, Andreas Steiner, Daniel Keysers, Alexander Kolesnikov, and Lucas
Beyer. <a href="https://arxiv.org/abs/2111.07991">LiT: Zero-shot transfer with locked-image text tuning</a>. In Proceedings of the IEEE/CVF conference
on computer vision and pattern recognition, pages 18123â€“18133, 2022b.&#160;<a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
</ol>
</div>







  
  




  



      
    </article>
  </div>

          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/LouisStefanuto" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/in/louis-stefanuto/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../../../..", "features": ["navigation.tabs", "navigation.expand"], "search": "../../../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../../../assets/javascripts/bundle.92b07e13.min.js"></script>
      
        <script src="../../../../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>